{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CuoiKy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk7jVQAlXl4o",
        "outputId": "4a38c053-ba06-4b32-dc5b-38d4cef2e9b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#ket noi voi drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "fUiPL5h-XtGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Final'\n",
        "\n",
        "train_datagen =ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "# Tạo bộ dữ liệu training set\n",
        "training_set=train_datagen.flow_from_directory('/content/drive/MyDrive/Final/Train',target_size=(256,256), batch_size=128, class_mode='categorical')\n",
        "\n",
        "# Tạo bộ dữ liệu validation\n",
        "validation=train_datagen.flow_from_directory('/content/drive/MyDrive/Final/validation',target_size=(256,256), batch_size=128, class_mode='categorical')\n",
        "\n",
        "# Các nhãn có trong bộ dữ liệu training set\n",
        "training_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPC-GMppYYI0",
        "outputId": "d1e5986c-4c43-4c1d-b55d-6d265d71660b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3990 images belonging to 10 classes.\n",
            "Found 1006 images belonging to 10 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Asagi': 0,\n",
              " 'Bekko': 1,\n",
              " 'Difference': 2,\n",
              " 'Hikarimuji mono': 3,\n",
              " 'Kohaku': 4,\n",
              " 'Sanke': 5,\n",
              " 'Showa': 6,\n",
              " 'Shusui': 7,\n",
              " 'Tancho': 8,\n",
              " 'Utsuri': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_model(input_shape):\n",
        "    input_img = tf.keras.Input(shape=input_shape)\n",
        "    X = tfl.Conv2D(8, kernel_size=(4,4), strides=(1,1), padding='SAME')(input_img)\n",
        "    X = tfl.ReLU()(X)\n",
        "    X = tfl.MaxPool2D(pool_size=(8,8), strides=(8,8), padding='SAME')(X)\n",
        "    X = tfl.Conv2D(16, kernel_size=(2,2), strides=(1,1), padding='SAME')(X)\n",
        "    X = tfl.ReLU()(X)\n",
        "    X = tfl.MaxPool2D(pool_size=(4,4), strides=(4,4), padding='SAME')(X)\n",
        "    X = tfl.Flatten()(X)\n",
        "    outputs = tfl.Dense(units=10, activation=\"softmax\")(X)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "_vqINWRLZBqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3),padding = 'same', kernel_initializer = 'he_uniform', input_shape = (256,256,3), activation = 'relu'))\n",
        "\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding = 'same',  kernel_initializer = 'he_uniform', activation = 'relu'))\n",
        "\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(128,(3,3), padding='same',  kernel_initializer = 'he_uniform', activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = 'relu',  kernel_initializer = 'he_uniform'))\n",
        "\n",
        "model.add(Dense(output, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpOd9GBZR7q",
        "outputId": "c19bd371-7956-4dc4-ea6f-62a86399e4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 131072)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,001,866\n",
            "Trainable params: 17,001,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam' , metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(training_set, epochs=20, validation_data=validation, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqElKPVLZVjT",
        "outputId": "16e7f472-1467-41d7-a48f-0d57bbbc3888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 1700s 52s/step - loss: 4.7025 - accuracy: 0.3298 - val_loss: 1.3241 - val_accuracy: 0.5586\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 1399s 44s/step - loss: 0.9520 - accuracy: 0.6862 - val_loss: 0.6170 - val_accuracy: 0.8121\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 1407s 44s/step - loss: 0.3746 - accuracy: 0.8925 - val_loss: 0.4011 - val_accuracy: 0.8777\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 1402s 44s/step - loss: 0.1770 - accuracy: 0.9524 - val_loss: 0.2752 - val_accuracy: 0.9185\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 1380s 43s/step - loss: 0.0613 - accuracy: 0.9827 - val_loss: 0.2958 - val_accuracy: 0.9125\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 1382s 43s/step - loss: 0.0403 - accuracy: 0.9922 - val_loss: 0.2315 - val_accuracy: 0.9344\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 1382s 43s/step - loss: 0.0348 - accuracy: 0.9947 - val_loss: 0.2787 - val_accuracy: 0.9334\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 1370s 43s/step - loss: 0.0465 - accuracy: 0.9902 - val_loss: 0.2486 - val_accuracy: 0.9374\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 1379s 43s/step - loss: 0.0217 - accuracy: 0.9950 - val_loss: 0.2948 - val_accuracy: 0.9344\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 1381s 43s/step - loss: 0.0387 - accuracy: 0.9922 - val_loss: 0.2644 - val_accuracy: 0.9364\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 1374s 43s/step - loss: 0.0463 - accuracy: 0.9875 - val_loss: 0.3285 - val_accuracy: 0.9225\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 1381s 43s/step - loss: 0.0406 - accuracy: 0.9917 - val_loss: 0.2949 - val_accuracy: 0.9334\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 1381s 44s/step - loss: 0.0199 - accuracy: 0.9967 - val_loss: 0.2535 - val_accuracy: 0.9394\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 1372s 43s/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.2170 - val_accuracy: 0.9503\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 1365s 43s/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.2459 - val_accuracy: 0.9414\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 1372s 43s/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.2307 - val_accuracy: 0.9443\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 1371s 43s/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.2190 - val_accuracy: 0.9533\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 1368s 43s/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.2040 - val_accuracy: 0.9563\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 1376s 43s/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.2062 - val_accuracy: 0.9513\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 1380s 43s/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.2113 - val_accuracy: 0.9543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá độ chính xác của mô hình \n",
        "Score=model.evaluate(training_set,verbose=0)\n",
        "print('Train Loss', Score[0])\n",
        "print('Train Accuracy', Score[1])"
      ],
      "metadata": {
        "id": "HAnue-SuZ0tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a83b2d4-6159-4ea2-9882-13a7e3ebd2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0057297698222100735\n",
            "Train Accuracy 0.9984962344169617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Vẽ đồ thị giữa số lần học (Epochs) và độ chính xác (Accuracy)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train','Validation'])\n",
        "plt.show\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "n1JS9-MzfRJj",
        "outputId": "caa8aeb4-cf83-4cce-c708-b822e9591395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu lại\n",
        "model.save(\"fish_KOI.h5\")"
      ],
      "metadata": {
        "id": "rUYGK53bfV-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo và sử dụng các thư viện sau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils import validation \n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Tải mô hình \n",
        "model_KOI=load_model('/content/drive/MyDrive/Final/fish_KOI.h5')"
      ],
      "metadata": {
        "id": "X1jXh6l_xsAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=\"/content/drive/MyDrive/Final/test\"\n",
        "for i in os.listdir(test):\n",
        "  link = test+'/'+i\n",
        "  img=load_img(link,target_size=(256,256))\n",
        "  # plt.imshow(img)\n",
        "  img=img_to_array(img)\n",
        "  img=img.astype('float32')\n",
        "  img=img/255\n",
        "  img=np.expand_dims(img,axis=0)\n",
        "  result=model_KOI.predict(img)\n",
        "  if round(result[0][0])==1:\n",
        "    prediction='Asagi'\n",
        "  if round(result[0][1])==1:\n",
        "    prediction='Bekko'\n",
        "  if round(result[0][2])==1:\n",
        "    prediction='Difference'\n",
        "  if round(result[0][3])==1:\n",
        "    prediction='Hikarimuji mono'\n",
        "  if round(result[0][4])==1:\n",
        "    prediction='Kohaku'\n",
        "  if round(result[0][5])==1:\n",
        "    prediction='Sanke'\n",
        "  if round(result[0][6])==1:\n",
        "    prediction='Showa'\n",
        "  if round(result[0][7])==1:\n",
        "    prediction='Shusui'\n",
        "  if round(result[0][8])==1:\n",
        "    prediction='Tancho'\n",
        "  if round(result[0][9])==1:\n",
        "    prediction='Utsuri'\n",
        "  print(prediction)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFXv_FMgPei2",
        "outputId": "ba785c18-71e0-4d63-820b-45b411741ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kohaku\n",
            "Showa\n",
            "Kohaku\n",
            "Showa\n",
            "Showa\n",
            "Asagi\n",
            "Asagi\n",
            "Hikarimuji mono\n",
            "Showa\n",
            "Kohaku\n",
            "Hikarimuji mono\n",
            "Sanke\n",
            "Showa\n",
            "Difference\n",
            "Difference\n",
            "Shusui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Asagi', 'Bekko', 'Difference', 'Hikarimuji mono', 'Kohaku','Sanke', \n",
        "           'Showa', 'Shusui', 'Tancho', 'Utsuri']\n",
        "\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test=\"/content/drive/MyDrive/Final/test\"\n",
        "address = []\n",
        "for i in os.listdir(test):\n",
        "  link = test+'/'+i\n",
        "  address.append(link)\n",
        "  \n",
        "\n",
        "  \n",
        "for add in address:\n",
        "  img = load_img(add,target_size=(256,256))\n",
        "  plt.imshow(img)\n",
        "  img = img_to_array(img)\n",
        "  img=img.reshape(1,256,256,3)\n",
        "  img=img.astype('float32')\n",
        "  img = img/255\n",
        "  print(\"Kết quả dự đoán:\")\n",
        "  print(classes[np.argmax(model_KOI.predict(img))])\n",
        "\n",
        "# print(address)\n",
        "# /content/drive/MyDrive/Final/test/1 (3).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (14).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (13).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (2).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (16).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (11).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (10).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (1).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (1).jpeg\n",
        "# /content/drive/MyDrive/Final/test/1 (9).jpg\n",
        "# /content/drive/MyDrive/Final/test/1 (5).jpg\n",
        "# /content/drive/MyDrive/Final/test/32.jpg\n",
        "# /content/drive/MyDrive/Final/test/29.jpg\n",
        "# /content/drive/MyDrive/Final/test/5.jpg\n",
        "# /content/drive/MyDrive/Final/test/4.jpg\n",
        "# /content/drive/MyDrive/Final/test/10.jpg"
      ],
      "metadata": {
        "id": "HUQSc9Y51M9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################# realtime\n",
        "from IPython.display import display, Javascript, Image\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Bấm vào video để dừng</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "tq_Wm6Nz421y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "AIEewAIVUqLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import cv2\n",
        "from keras.models import  load_model\n",
        "\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Đang lấy hình ảnh...'\n",
        "# initialze bounding box to emptyA\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "# Load model Nhận diện\n",
        "model_file_path = \"/content/drive/MyDrive/Final/fish_KOI.h5\"\n",
        "\n",
        "vggmodel = load_model(model_file_path)\n",
        "# vggmodel1 = load_model(model_file_path_1)\n",
        "# vggmodel2= load_model(model_file_path_2)\n",
        "\n",
        "# classes =['Asagi', 'Bekko', 'Difference', 'Hikarimuji mono', 'Kohaku','Sanke', 'Showa', 'Shusui', 'Tancho', 'Utsuri']\n",
        "\n",
        "classes =['Asagi', 'Bekko', 'Bekko', 'Hikarimuji mono', 'Kohaku','Sanke', 'Showa', 'Shusui', 'Tancho', 'Utsuri']\n",
        "\n",
        "while True:\n",
        "    # Đọc ảnh trả về từ JS\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # Resize để đưa vào model\n",
        "    frame_p = cv2.resize(frame, dsize=(256,256))\n",
        "    # frame_p1 = cv2.resize(frame, dsize=(70,70))\n",
        "    # frame_p2 = cv2.resize(frame, dsize=(100,100))\n",
        "\n",
        "    tensor = np.expand_dims(frame_p, axis=0)\n",
        "    # tensor1 = np.expand_dims(frame_p1, axis=0)\n",
        "    # tensor2 = np.expand_dims(frame_p2, axis=0)\n",
        "\n",
        "    # Feed vào mạng\n",
        "    pred = vggmodel.predict(tensor)\n",
        "    \n",
        "    # pred1 = vggmodel1.predict(tensor1)\n",
        "    # pred2 = vggmodel2.predict(tensor2)\n",
        "\n",
        "    class_id = np.argmax(pred)\n",
        "    # class_id_1 = np.argmax(pred1)\n",
        "    # class_id_2 = np.argmax(pred2)\n",
        "    # label =['Sleep','No Sleep']\n",
        "    # if class_id == 2 or class_id == 3:\n",
        "    #   class_name = label[1] \n",
        "    # if class_id == 1 or class_id == 4:\n",
        "    #   class_name = label[0] \n",
        "    class_name = classes[class_id]  \n",
        "   \n",
        "\n",
        "    # class_name_1 = classes1[class_id_1]\n",
        "    # class_name_2 = classes2[class_id_2]\n",
        "    # Vẽ lên một ảnh để tẹo nữa overlay\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "   \n",
        "    bbox_array = cv2.putText(bbox_array, \"{}\".format(class_name),\n",
        "                        (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (0, 255,0), 2)\n",
        "    \n",
        "    y_pred = vggmodel.predict(tensor)\n",
        "    a = y_pred.max()\n",
        "    #a = a*100\n",
        "    bbox_array = cv2.putText(bbox_array, \"{}\".format(a),\n",
        "                        (400, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (0, 255,0), 2)   \n",
        "\n",
        "     \n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "gX7r-NTJUzWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jNJkCv2NVLjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}